{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Import libraries and packages\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import init\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# from fastai.metrics import DynaGraph/VGAELast.ipynb*\n",
    "from fastai.basics import *\n",
    "from fastai.imports import *\n",
    "from fastai.torch_core import *\n",
    "from fastcore.basics import *\n",
    "from fastcore.dispatch import *\n",
    "from fastcore.foundation import *\n",
    "from fastcore.imports import *\n",
    "from fastcore.meta import *\n",
    "from fastcore.test import *\n",
    "\n",
    "# Seeds we tried: 42, 1992, 250, 213, 1709\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# DEVICE = torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cd Data/eICU_Data # MIMIC_III_Data "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train = np.load('X_train_multilabel_full_42.npy', mmap_mode='c') # Add MIMICX in the name for MIMIC III data\n",
    "X_val = np.load('X_val_multilabel_full_42.npy', mmap_mode='c')\n",
    "X_test = np.load('X_test_multilabel_full_42.npy', mmap_mode='c')\n",
    "y_train = np.load('y_train_multilabel_full_42.npy', mmap_mode='c')\n",
    "y_val = np.load('y_val_multilabel_full_42.npy', mmap_mode='c')\n",
    "y_test = np.load('y_test_multilabel_full_42.npy', mmap_mode='c')\n",
    "\n",
    "# LSTM hidden embeddings flipped later\n",
    "X_train = np.swapaxes(X_train, 1, 2)\n",
    "X_val = np.swapaxes(X_val, 1, 2)\n",
    "X_test = np.swapaxes(X_test, 1, 2)\n",
    "\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_val = torch.from_numpy(X_val)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_val = torch.from_numpy(y_val)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "X_train = X_train[:, None, :, :]\n",
    "assert X_train.shape == (974, 1, 80, 24)\n",
    "\n",
    "X_val = X_val[:, None, :, :]\n",
    "assert X_val.shape == (172, 1, 80, 24)\n",
    "\n",
    "X_test = X_test[:, None, :, :]\n",
    "assert X_test.shape == (287, 1, 80, 24)\n",
    "\n",
    "# init [num_variables, seq_length, num_classes]\n",
    "num_nodes = X_val.size(-2)\n",
    "\n",
    "seq_length = X_val.size(-1)\n",
    "\n",
    "num_classes = 5 # change to 10 for MIMIX-III\n",
    "\n",
    "# convert data & labels to TensorDataset\n",
    "train_dataset = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "val_dataset = TensorDataset(torch.tensor(X_val), torch.tensor(y_val))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))\n",
    "\n",
    "# data_loader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=True,\n",
    "                                            pin_memory=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=True,\n",
    "                                            pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                            batch_size=287,\n",
    "                                            shuffle=False,\n",
    "                                            pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "# %% [code]\n",
    "class multi_shallow_embedding(nn.Module):\n",
    "\n",
    "    def __init__(self, num_nodes, k_neighs, num_graphs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_nodes = num_nodes\n",
    "        self.k = k_neighs\n",
    "        self.num_graphs = num_graphs\n",
    "\n",
    "        self.emb_s = Parameter(Tensor(num_graphs, num_nodes, 1))\n",
    "        self.emb_t = Parameter(Tensor(num_graphs, 1, num_nodes))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.xavier_uniform_(self.emb_s)\n",
    "        init.xavier_uniform_(self.emb_t)\n",
    "\n",
    "\n",
    "    def forward(self, device):\n",
    "\n",
    "        # adj: [G, N, N]\n",
    "        adj = torch.matmul(self.emb_s, self.emb_t).to(device)\n",
    "\n",
    "        # remove self-loop\n",
    "        adj = adj.clone()\n",
    "        idx = torch.arange(self.num_nodes, dtype=torch.long, device=device)\n",
    "        adj[:, idx, idx] = float('-inf')\n",
    "\n",
    "        # top-k-edge adj\n",
    "        adj_flat = adj.reshape(self.num_graphs, -1)\n",
    "        indices = adj_flat.topk(k=self.k)[1].reshape(-1)\n",
    "\n",
    "        idx = torch.tensor([ i//self.k for i in range(indices.size(0)) ], device=device)\n",
    "\n",
    "        adj_flat = torch.zeros_like(adj_flat).clone()\n",
    "        adj_flat[idx, indices] = 1.\n",
    "        adj = adj_flat.reshape_as(adj)\n",
    "\n",
    "        return adj\n",
    "\n",
    "\n",
    "class Group_Linear(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, groups=1, bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.groups = groups\n",
    "\n",
    "        self.group_mlp = nn.Conv2d(in_channels * groups, out_channels * groups, kernel_size=(1, 1), groups=groups, bias=bias)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.group_mlp.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor, is_reshape: False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): [B, C, N, F] (if not is_reshape), [B, C, G, N, F//G] (if is_reshape)\n",
    "        \"\"\"\n",
    "        B = x.size(0)\n",
    "        C = x.size(1)\n",
    "        N = x.size(-2)\n",
    "        G = self.groups\n",
    "\n",
    "        if not is_reshape:\n",
    "            # x: [B, C_in, G, N, F//G]\n",
    "            x = x.reshape(B, C, N, G, -1).transpose(2, 3)\n",
    "        # x: [B, G*C_in, N, F//G]\n",
    "        x = x.transpose(1, 2).reshape(B, G*C, N, -1)\n",
    "\n",
    "        out = self.group_mlp(x)\n",
    "        out = out.reshape(B, G, self.out_channels, N, -1).transpose(1, 2)\n",
    "\n",
    "        # out: [B, C_out, G, N, F//G]\n",
    "        return out\n",
    "\n",
    "\n",
    "class DenseGCNConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, groups=1, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.lin = Group_Linear(in_channels, out_channels, groups, bias=False)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        init.zeros_(self.bias)\n",
    "\n",
    "    def norm(self, adj: Tensor, add_loop):\n",
    "        if add_loop:\n",
    "            adj = adj.clone()\n",
    "            idx = torch.arange(adj.size(-1), dtype=torch.long, device=adj.device)\n",
    "            adj[:, idx, idx] += 1\n",
    "\n",
    "        deg_inv_sqrt = adj.sum(-1).clamp(min=1).pow(-0.5)\n",
    "\n",
    "        adj = deg_inv_sqrt.unsqueeze(-1) * adj * deg_inv_sqrt.unsqueeze(-2)\n",
    "\n",
    "        return adj\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor, adj: Tensor, add_loop=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): [B, C, N, F]\n",
    "            adj (Tensor): [B, G, N, N]\n",
    "        \"\"\"\n",
    "        adj = self.norm(adj, add_loop).unsqueeze(1)\n",
    "\n",
    "        # x: [B, C, G, N, F//G]\n",
    "        x = self.lin(x, False)\n",
    "\n",
    "        out = torch.matmul(adj, x)\n",
    "\n",
    "        # out: [B, C, N, F]\n",
    "        B, C, _, N, _ = out.size()\n",
    "        out = out.transpose(2, 3).reshape(B, C, N, -1)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out = out.transpose(1, -1) + self.bias\n",
    "            out = out.transpose(1, -1)\n",
    "\n",
    "        return out\n",
    "\n",
    "class VGAE(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, groups=1, eps=0, train_eps=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp = Group_Linear(in_channels, out_channels, groups, bias=False)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder_mean = Group_Linear(in_channels, out_channels, groups, bias=False)\n",
    "        self.encoder_logvar = Group_Linear(in_channels, out_channels, groups, bias=False)\n",
    "\n",
    "        # Decoder\n",
    "        self.mlp = Group_Linear(out_channels, in_channels, groups, bias=False)  # Adjust output channels\n",
    "\n",
    "\n",
    "        self.init_eps = eps\n",
    "        if train_eps:\n",
    "            self.eps = Parameter(Tensor([eps]))\n",
    "        else:\n",
    "            self.register_buffer('eps', Tensor([eps]))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.mlp.reset_parameters()\n",
    "        self.eps.data.fill_(self.init_eps)\n",
    "\n",
    "    def norm(self, adj: Tensor, add_loop):\n",
    "        if add_loop:\n",
    "            adj = adj.clone()\n",
    "            idx = torch.arange(adj.size(-1), dtype=torch.long, device=adj.device)\n",
    "            adj[..., idx, idx] += 1\n",
    "\n",
    "        deg_inv_sqrt = adj.sum(-1).clamp(min=1).pow(-0.5)\n",
    "\n",
    "        adj = deg_inv_sqrt.unsqueeze(-1) * adj * deg_inv_sqrt.unsqueeze(-2)\n",
    "\n",
    "        return adj\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        # Add an epsilon to prevent very large values\n",
    "        epsilon = 1e-7\n",
    "        std = torch.exp(0.5 * logvar) + epsilon\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def forward(self, x: Tensor, adj: Tensor, add_loop=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): [B, C, N, F]\n",
    "            adj (Tensor): [G, N, N]\n",
    "        \"\"\"\n",
    "        B, C, N, _ = x.size()\n",
    "        G = adj.size(0)\n",
    "\n",
    "        # adj-norm\n",
    "        adj = self.norm(adj, add_loop=False)\n",
    "\n",
    "        # x: [B, C, G, N, F//G]\n",
    "        x = x.reshape(B, C, N, G, -1).transpose(2, 3)\n",
    "\n",
    "        out = torch.matmul(adj, x)\n",
    "\n",
    "        # DYNAMIC\n",
    "        x_pre = x[:, :, :-1, ...]\n",
    "\n",
    "        # out = x[:, :, 1:, ...] + x_pre\n",
    "        out[:, :, 1:, ...] = out[:, :, 1:, ...] + x_pre\n",
    "        # out = torch.cat( [x[:, :, 0, ...].unsqueeze(2), out], dim=2 )\n",
    "\n",
    "        if add_loop:\n",
    "            out = (1 + self.eps) * x + out\n",
    "\n",
    "        # out: [B, C, G, N, F//G]\n",
    "        out = self.mlp(out, True)\n",
    "\n",
    "        # out: [B, C, N, F]\n",
    "        C = out.size(1)\n",
    "        out2 = out.transpose(2, 3).reshape(B, C, N, -1)\n",
    "\n",
    "        # Variational encoding\n",
    "        mean = self.mlp(x,True)\n",
    "        logvar = self.mlp(x,True)\n",
    "\n",
    "\n",
    "        return out2 , logvar, mean\n",
    "\n",
    "class Dense_TimeDiffPool2d(nn.Module):\n",
    "\n",
    "    def __init__(self, pre_nodes, pooled_nodes, kern_size, padding):\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO: add Normalization\n",
    "        self.time_conv = nn.Conv2d(pre_nodes, pooled_nodes, (1, kern_size), padding=(0, padding))\n",
    "\n",
    "        self.re_param = Parameter(Tensor(kern_size, 1))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.time_conv.reset_parameters()\n",
    "        init.kaiming_uniform_(self.re_param, nonlinearity='relu')\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor, adj: Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): [B, C, N, F]\n",
    "            adj (Tensor): [G, N, N]\n",
    "        \"\"\"\n",
    "        x = x.transpose(1, 2)\n",
    "        out = self.time_conv(x)\n",
    "        out = out.transpose(1, 2)\n",
    "\n",
    "        # s: [ N^(l+1), N^l, 1, K ]\n",
    "        s = torch.matmul(self.time_conv.weight, self.re_param).view(out.size(-2), -1)\n",
    "\n",
    "        out_adj = torch.matmul(torch.matmul(s, adj), s.transpose(0, 1))\n",
    "\n",
    "        return out, out_adj\n",
    "\n",
    "class GNNStack(nn.Module):\n",
    "\n",
    "    def __init__(self, gnn_model_type, num_layers, groups, pool_ratio, kern_size,\n",
    "                 in_dim, hidden_dim, out_dim,\n",
    "                 seq_len, num_nodes, num_classes, dropout=0.7, activation=nn.ReLU()):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention_matrix = nn.Parameter(torch.randn(groups, num_nodes, num_nodes))\n",
    "        nn.init.xavier_uniform_(self.attention_matrix)\n",
    "        #******************************************************************************\n",
    "\n",
    "        k_neighs = self.num_nodes = num_nodes\n",
    "\n",
    "        self.num_graphs = groups\n",
    "\n",
    "        self.num_feats = seq_len\n",
    "        if seq_len % groups:\n",
    "            self.num_feats += ( groups - seq_len % groups )\n",
    "        self.g_constr = multi_shallow_embedding(num_nodes, k_neighs, self.num_graphs)\n",
    "\n",
    "        gnn_model, heads = self.build_gnn_model(gnn_model_type)\n",
    "\n",
    "        assert num_layers >= 1, 'Error: Number of layers is invalid.'\n",
    "        assert num_layers == len(kern_size), 'Error: Number of kernel_size should equal to number of layers.'\n",
    "        paddings = [ (k - 1) // 2 for k in kern_size ]\n",
    "\n",
    "        self.tconvs = nn.ModuleList(\n",
    "            [nn.Conv2d(1, in_dim, (1, kern_size[0]), padding=(0, paddings[0]))] +\n",
    "            [nn.Conv2d(heads * in_dim, hidden_dim, (1, kern_size[layer+1]), padding=(0, paddings[layer+1])) for layer in range(num_layers - 2)] +\n",
    "            [nn.Conv2d(heads * hidden_dim, out_dim, (1, kern_size[-1]), padding=(0, paddings[-1]))]\n",
    "        )\n",
    "\n",
    "        self.lstm_layers = nn.ModuleList()\n",
    "        self.lstm_layers.append(nn.RNN(input_size=24, hidden_size=in_dim * 24, batch_first=True))\n",
    "        for _ in range(1, num_layers - 2):\n",
    "            self.lstm_layers.append(nn.RNN(input_size=in_dim * 24, hidden_size=hidden_dim * 24, batch_first=True))\n",
    "        self.lstm_layers.append(nn.RNN(input_size=hidden_dim * 24, hidden_size=out_dim * 24, batch_first=True))\n",
    "\n",
    "        self.gconvs = nn.ModuleList(\n",
    "            [gnn_model(in_dim, heads * in_dim, groups)] +\n",
    "            [gnn_model(hidden_dim, heads * hidden_dim, groups) for _ in range(num_layers - 2)] +\n",
    "            [gnn_model(out_dim, heads * out_dim, groups)]\n",
    "        )\n",
    "\n",
    "        self.bns = nn.ModuleList(\n",
    "            [nn.BatchNorm2d(heads * in_dim)] +\n",
    "            [nn.BatchNorm2d(heads * hidden_dim) for _ in range(num_layers - 2)] +\n",
    "            [nn.BatchNorm2d(heads * out_dim)]\n",
    "        )\n",
    "\n",
    "        self.left_num_nodes = []\n",
    "        for layer in range(num_layers + 1):\n",
    "            left_node = round( num_nodes * (1 - (pool_ratio*layer)) )\n",
    "            if left_node > 0:\n",
    "                self.left_num_nodes.append(left_node)\n",
    "            else:\n",
    "                self.left_num_nodes.append(1)\n",
    "        self.diffpool = nn.ModuleList(\n",
    "            [Dense_TimeDiffPool2d(self.left_num_nodes[layer], self.left_num_nodes[layer+1], kern_size[layer], paddings[layer]) for layer in range(num_layers - 1)] +\n",
    "            [Dense_TimeDiffPool2d(self.left_num_nodes[-2], self.left_num_nodes[-1], kern_size[-1], paddings[-1])]\n",
    "        )\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.activation = activation\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.linear = nn.Linear(heads * out_dim, num_classes)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lstm, gconv, bn, pool in zip(self.lstm_layers, self.gconvs, self.bns, self.diffpool):\n",
    "            lstm.reset_parameters()\n",
    "            gconv.reset_parameters()\n",
    "            bn.reset_parameters()\n",
    "            pool.reset_parameters()\n",
    "\n",
    "        self.linear.reset_parameters()\n",
    "\n",
    "    def build_gnn_model(self, model_type):\n",
    "        if model_type == 'dyGCN2d':\n",
    "            return DenseGCNConv2d, 1\n",
    "        if model_type == 'VGAE':\n",
    "            return VGAE, 1\n",
    "\n",
    "\n",
    "    def forward(self, inputs: Tensor):\n",
    "\n",
    "        if inputs.size(-1) % self.num_graphs:\n",
    "            pad_size = (self.num_graphs - inputs.size(-1) % self.num_graphs) / 2\n",
    "            x = F.pad(inputs, (int(pad_size), ceil(pad_size)), mode='constant', value=0.0)\n",
    "        else:\n",
    "            x = inputs\n",
    "\n",
    "        adj = self.g_constr(x.device)\n",
    "   \n",
    "        #*******************************************************************\n",
    "        # Attention layer \n",
    "        attention_scores = F.softmax(self.attention_matrix, dim=-1)  \n",
    "        adj = adj * attention_scores \n",
    "        # print(attention_scores,\"attention_scores\")\n",
    "        #*******************************************************************    \n",
    "        \n",
    "        for lstm, gconv, bn, pool in zip(self.lstm_layers, self.gconvs, self.bns, self.diffpool):           \n",
    "            s=x.shape[1]\n",
    "            if s==1:\n",
    "               x1=x.repeat(1, 128, 1,1)\n",
    "            else:\n",
    "               x1=x.repeat(1, 2, 1,1)    \n",
    "            batch_size, channels, seq_len, features = x.size()\n",
    "            x = x.view(batch_size, seq_len, channels * features)\n",
    "            # Apply LSTM layer\n",
    "            x, _ = lstm(x)\n",
    "            x = torch.reshape(x, (batch_size, -1, seq_len, features))\n",
    "            x=x+x1\n",
    "\n",
    "            temp, logvar, mean = gconv(x, adj)\n",
    "            \n",
    "            x, adj = pool(temp, adj)\n",
    "\n",
    "            x = self.activation(bn(x))\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            \n",
    "\n",
    "        out = self.global_pool(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out,logvar, mean,adj"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Metrics\n",
    "# %% [code]\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "# %% [code]\n",
    "def balanced_accuracy_multi(inp, targ, thresh=0.5, sigmoid=True):\n",
    "    \"Computes balanced accuracy when `inp` and `targ` are the same size.\"\n",
    "\n",
    "    if sigmoid: inp = inp.sigmoid()\n",
    "    pred = inp>thresh\n",
    "\n",
    "    correct = pred==targ.bool()\n",
    "    TP = torch.logical_and(correct,  (targ==1).bool()).sum()\n",
    "    TN = torch.logical_and(correct,  (targ==0).bool()).sum()\n",
    "    FN = torch.logical_and(~correct, (targ==1).bool()).sum()\n",
    "    FP = torch.logical_and(~correct, (targ==0).bool()).sum()\n",
    "\n",
    "    TPR = TP/(TP+FN)\n",
    "    TNR = TN/(TN+FP)\n",
    "    balanced_accuracy = (TPR+TNR)/2\n",
    "    return balanced_accuracy\n",
    "\n",
    "# %% [code]\n",
    "def Fbeta_multi(inp, targ, beta=1.0, thresh=0.5, sigmoid=True):\n",
    "    \"Computes Fbeta when `inp` and `targ` are the same size.\"\n",
    "\n",
    "    if sigmoid: inp = inp.sigmoid()\n",
    "    pred = inp>thresh\n",
    "\n",
    "    correct = pred==targ.bool()\n",
    "    TP = torch.logical_and(correct,  (targ==1).bool()).sum()\n",
    "    TN = torch.logical_and(correct,  (targ==0).bool()).sum()\n",
    "    FN = torch.logical_and(~correct, (targ==1).bool()).sum()\n",
    "    FP = torch.logical_and(~correct, (targ==0).bool()).sum()\n",
    "\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    beta2 = beta*beta\n",
    "\n",
    "    if precision+recall > 0:\n",
    "        Fbeta = (1+beta2)*precision*recall/(beta2*precision+recall)\n",
    "    else:\n",
    "        Fbeta = 0\n",
    "    return Fbeta\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "def recall_multi(inp, targ, thresh=0.5, sigmoid=True):\n",
    "    \"Computes recall when `inp` and `targ` are the same size.\"\n",
    "\n",
    "    if sigmoid: inp = inp.sigmoid()\n",
    "    pred = inp>thresh\n",
    "\n",
    "    correct = pred==targ.bool()\n",
    "    TP = torch.logical_and(correct,  (targ==1).bool()).sum()\n",
    "    FN = torch.logical_and(~correct, (targ==1).bool()).sum()\n",
    "\n",
    "    recall = TP/(TP+FN)\n",
    "    return recall"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6seT1-CkH46o",
    "outputId": "48245d5a-3805-4251-86b5-f7c22072ceed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_784923/733260590.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_dataset = TensorDataset(torch.tensor(data_train), torch.tensor(label_train))\n",
      "/tmp/ipykernel_784923/733260590.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_dataset = TensorDataset(torch.tensor(data_val), torch.tensor(label_val))\n",
      "/tmp/ipykernel_784923/733260590.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_dataset = TensorDataset(torch.tensor(data_test), torch.tensor(label_test))\n",
      "/home/engs2455/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "/tmp/ipykernel_784923/733260590.py:755: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  augmented_data_pos = torch.tensor(data * mask)\n",
      "/home/engs2455/anaconda3/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/engs2455/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL, loss 1658122168.5581396, acc 0.5, f1 0.0, sens 0.0\n",
      "VAL, loss 3006548616.9302325, acc 0.5, f1 0.0, sens 0.0\n",
      "VAL, loss 2263467383.0697675, acc 0.5, f1 0.0, sens 0.0\n",
      "VAL, loss 77670356938275.72, acc 0.5039410591125488, f1 0.017718717455863953, sens 0.009302325546741486\n",
      "VAL, loss 97733568195750.7, acc 0.5702905654907227, f1 0.25954240560531616, sens 0.1885342001914978\n",
      "VAL, loss 1640043176507.535, acc 0.5180749893188477, f1 0.08142071962356567, sens 0.04724252596497536\n",
      "VAL, loss 23568506131670.324, acc 0.535615086555481, f1 0.14530904591083527, sens 0.08787693828344345\n",
      "VAL, loss 645322037962.4186, acc 0.5240487456321716, f1 0.11106186360120773, sens 0.06597691029310226\n",
      "VAL, loss 11616764754443.906, acc 0.5668613314628601, f1 0.23858487606048584, sens 0.16689147055149078\n",
      "VAL, loss 42276813764369.86, acc 0.5672913193702698, f1 0.24823006987571716, sens 0.1676645129919052\n",
      "VAL, loss 58038519521851.53, acc 0.5820856690406799, f1 0.27314531803131104, sens 0.21186725795269012\n",
      "VAL, loss 708074927889.8605, acc 0.5609992146492004, f1 0.22673317790031433, sens 0.15946844220161438\n",
      "VAL, loss 182372727784.18604, acc 0.5043211579322815, f1 0.02540913224220276, sens 0.014094432815909386\n",
      "VAL, loss 127871894361.30232, acc 0.5957626700401306, f1 0.2957025468349457, sens 0.23178283870220184\n",
      "VAL, loss 4375378998010.0464, acc 0.5788013339042664, f1 0.2655346691608429, sens 0.17550751566886902\n",
      "VAL, loss 262937917297.11627, acc 0.5629959106445312, f1 0.2186439484357834, sens 0.14913851022720337\n",
      "VAL, loss 429265257972.093, acc 0.6321606040000916, f1 0.3691678047180176, sens 0.3189407289028168\n",
      "VAL, loss 2407844812752.372, acc 0.6113923788070679, f1 0.3396906852722168, sens 0.31590595841407776\n",
      "VAL, loss 952468338735.6279, acc 0.5769363641738892, f1 0.2647874355316162, sens 0.18557238578796387\n",
      "VAL, loss 182018011993.30234, acc 0.6039016842842102, f1 0.32654571533203125, sens 0.25034528970718384\n",
      "VAL, loss 504775870702.1395, acc 0.5792105793952942, f1 0.2710537910461426, sens 0.17890487611293793\n",
      "VAL, loss 10721541445965.395, acc 0.6224159598350525, f1 0.35474079847335815, sens 0.3269849419593811\n",
      "VAL, loss 40573117594123.91, acc 0.6044915318489075, f1 0.3169229328632355, sens 0.27682313323020935\n",
      "VAL, loss 34062009582.139534, acc 0.5734961032867432, f1 0.26507124304771423, sens 0.18247376382350922\n",
      "VAL, loss 74199162498.97675, acc 0.5737373232841492, f1 0.2563401460647583, sens 0.16138038039207458\n",
      "VAL, loss 44869559605.5814, acc 0.5741949081420898, f1 0.2664252817630768, sens 0.18261581659317017\n",
      "VAL, loss 14126025656.55814, acc 0.7019321322441101, f1 0.4237138032913208, sens 0.6144280433654785\n",
      "VAL, loss 9960493722.790697, acc 0.5766003727912903, f1 0.25591251254081726, sens 0.17841088771820068\n",
      "VAL, loss 532966773212.27905, acc 0.584148645401001, f1 0.2720116376876831, sens 0.20399920642375946\n",
      "VAL, loss 29652899119.627907, acc 0.6019095182418823, f1 0.3291587233543396, sens 0.24292069673538208\n",
      "VAL, loss 8413513805.395349, acc 0.6286299228668213, f1 0.36499321460723877, sens 0.3121841549873352\n",
      "VAL, loss 8288000285.767442, acc 0.5727623105049133, f1 0.2554933726787567, sens 0.16594956815242767\n",
      "VAL, loss 8428221088.744186, acc 0.7021358609199524, f1 0.41142264008522034, sens 0.7078708410263062\n",
      "VAL, loss 55376146432.0, acc 0.5961377620697021, f1 0.3179713189601898, sens 0.23219150304794312\n",
      "VAL, loss 221005178546.60464, acc 0.610969603061676, f1 0.3320363461971283, sens 0.2717406749725342\n",
      "VAL, loss 1051405139968.0, acc 0.6954809427261353, f1 0.4214327931404114, sens 0.6290667057037354\n",
      "VAL, loss 8821201189768.93, acc 0.5412390232086182, f1 0.1602487415075302, sens 0.09325867891311646\n",
      "VAL, loss 4195609915296.744, acc 0.5455982089042664, f1 0.17679138481616974, sens 0.10242922604084015\n",
      "VAL, loss 115065964020.09302, acc 0.5941476225852966, f1 0.31243711709976196, sens 0.23337635397911072\n",
      "VAL, loss 1849471674415.628, acc 0.5876049399375916, f1 0.29076969623565674, sens 0.19528160989284515\n",
      "VAL, loss 91493964299.90698, acc 0.7102566957473755, f1 0.42008647322654724, sens 0.729190468788147\n",
      "VAL, loss 1071293171950.1395, acc 0.5810768008232117, f1 0.26656800508499146, sens 0.1852031648159027\n",
      "VAL, loss 449159814215.44183, acc 0.5800317525863647, f1 0.26516011357307434, sens 0.17951789498329163\n",
      "VAL, loss 23264174568.186047, acc 0.5565371513366699, f1 0.20546256005764008, sens 0.12535764276981354\n",
      "VAL, loss 183956889409.48837, acc 0.6531258225440979, f1 0.40071672201156616, sens 0.40273627638816833\n",
      "VAL, loss 336118062532.4651, acc 0.6197852492332458, f1 0.35849201679229736, sens 0.30248263478279114\n",
      "VAL, loss 221957584657.86047, acc 0.581169843673706, f1 0.27609190344810486, sens 0.19099745154380798\n",
      "VAL, loss 5944022443698.6045, acc 0.5936086773872375, f1 0.3027998208999634, sens 0.22562766075134277\n",
      "VAL, loss 23800219058557.023, acc 0.6315143704414368, f1 0.37197786569595337, sens 0.32970330119132996\n",
      "VAL, loss 6616067372817.86, acc 0.5850395560264587, f1 0.2813434898853302, sens 0.19022978842258453\n",
      "VAL, loss 2034152008489.6743, acc 0.5863031148910522, f1 0.275282084941864, sens 0.22156661748886108\n",
      "VAL, loss 5986800182200.559, acc 0.5842800736427307, f1 0.28925803303718567, sens 0.19305764138698578\n",
      "VAL, loss 1085310522201.3024, acc 0.6026087403297424, f1 0.3220219016075134, sens 0.2518119513988495\n"
     ]
    }
   ],
   "source": [
    "model = GNNStack(gnn_model_type='VGAE', num_layers=2,\n",
    "                     groups=6, pool_ratio=0.2, kern_size=[11, 3],\n",
    "                     in_dim=128, hidden_dim=128, out_dim=256,\n",
    "                     seq_len=seq_length, num_nodes=num_nodes, num_classes=num_classes)\n",
    "\n",
    "\n",
    "torch.cuda.set_device(DEVICE)\n",
    "\n",
    "# collect cache\n",
    "gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "model = model.cuda(DEVICE)\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "criterion = nn.BCEWithLogitsLoss().cuda(DEVICE) # Here we show results without focal loss as it runs faster without\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5,\n",
    "                                                              patience=10, verbose=True)\n",
    "\n",
    "per=1e-8\n",
    "# %% [code]\n",
    "def regularization_loss(adj_original, adj_learned, lambda_reg):\n",
    "    return lambda_reg * torch.sum((adj_original - adj_learned) ** 2)\n",
    "\n",
    "def structural_loss(adj_original, adj_learned, mu):\n",
    "\n",
    "    adj_original_flat = adj_original.view(-1)\n",
    "    adj_learned_flat = adj_learned.view(-1)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    dot_product = torch.dot(adj_original_flat, adj_learned_flat)\n",
    "    norm_orig = torch.norm(adj_original_flat)\n",
    "    norm_learn = torch.norm(adj_learned_flat)\n",
    "    cosine_similarity = dot_product / (norm_orig * norm_learn)\n",
    "    \n",
    "    # Structural loss based on cosine distance\n",
    "    return mu * (1 - cosine_similarity)\n",
    "\n",
    "def initialize_adj_original(num_graphs, num_nodes):\n",
    "    # Random initialization for adj_original\n",
    "    adj_original = torch.rand(num_graphs, num_nodes, num_nodes, device=DEVICE)\n",
    "    # Set self-loops to zero using .fill_diagonal_() for each graph in the batch\n",
    "    for i in range(num_graphs):\n",
    "        adj_original[i].fill_diagonal_(0)\n",
    "    return adj_original\n",
    "\n",
    "def contrastive_criterion(output1, output2, negative_samples, margin=1.0):\n",
    "    # Positive similarity: Compare original and augmented data (output1 and output2)\n",
    "    positive_similarity = cosine_similarity(output1, output2)\n",
    "\n",
    "    # Negative similarity: Compare original data to negative samples\n",
    "    # negative_samples should be a tensor of embeddings from different classes\n",
    "    negative_similarity = cosine_similarity(output1.unsqueeze(1), negative_samples).max(dim=1)[0]\n",
    "\n",
    "    # The loss aims to ensure that the positive pair is closer than the hardest negative pair\n",
    "    return torch.clamp(margin - positive_similarity + negative_similarity, min=0).mean()\n",
    "\n",
    "def augment_data(data):\n",
    "    # Shuffling along the time axis (axis=2)\n",
    "    shuffled_data = data.clone()\n",
    "    batch_size, channels, time_length, features = data.shape\n",
    "    for i in range(batch_size):\n",
    "        # Generating a random permutation of indices from 0 to time_length - 1\n",
    "        idx = torch.randperm(time_length)\n",
    "        shuffled_data[i, :, :, :] = data[i, :, idx, :]\n",
    "    return shuffled_data\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, lr_scheduler,adj_original):\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc', ':6.2f')\n",
    "    f_1 = AverageMeter('F1', ':6.2f')\n",
    "    sensitivity = AverageMeter('Sens', ':6.2f')\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    adj_previous = adj_original\n",
    "    for count, (data, label) in enumerate(train_loader):\n",
    "\n",
    "        # data in cuda\n",
    "        augmented_data_neg = augment_data(data)\n",
    "\n",
    "        # Set 50 percent of the values to 0\n",
    "        mask = np.random.choice([0, 1], size=data.shape, p=[0.2, 0.8])\n",
    "\n",
    "        # Use the mask to set 50% of the elements to zero\n",
    "        augmented_data_pos = torch.tensor(data * mask)\n",
    "\n",
    "        data, augmented_data_neg = data.to(DEVICE).type(torch.float), augmented_data_neg.to(DEVICE).type(torch.float)\n",
    "        augmented_data_pos=augmented_data_pos.to(DEVICE).type(torch.float)\n",
    "        label = label.to(DEVICE).type(torch.float)\n",
    "\n",
    "        # Forward pass\n",
    "        output, logvar, mean,adj_learned = model(data)\n",
    "        # print(\"Original adj shape:\", adj_original.shape)\n",
    "        # print(\"Learned adj shape:\", adj_learned.shape)\n",
    "\n",
    "        loss_reg = regularization_loss(adj_original, adj_learned, 0.001)   \n",
    "        loss_struct = 0\n",
    "        if adj_previous is not None:\n",
    "            loss_struct = structural_loss(adj_previous, adj_learned, 0.001)\n",
    "        # augmented_output_pos, _, _ = model(augmented_data_pos) # removed the contrastive loss for speed, feel free to add if you have the compute\n",
    "        # augmented_data_neg, _, _ = model(augmented_data_neg)\n",
    "\n",
    "        # kl_divergence = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "        loss = criterion(output, label)+ loss_reg + loss_struct\n",
    "\n",
    "        # Contrastive loss\n",
    "        \n",
    "        # contrastive_loss = contrastive_criterion(output, augmented_output_pos,augmented_data_neg) # removed for computational speed, add if you choose\n",
    "        total_loss = loss \n",
    "        losses.update(loss.item(), data.size(0))\n",
    "        acc1 = balanced_accuracy_multi(output, label)\n",
    "        f1 = Fbeta_multi(output, label)\n",
    "        sens = recall_multi(output, label)\n",
    "        # contrastive_losses.update(contrastive_loss.item(), data.size(0))\n",
    "\n",
    "        top1.update(acc1, data.size(0))\n",
    "        f_1.update(f1, data.size(0))\n",
    "        sensitivity.update(sens, data.size(0))\n",
    "\n",
    "        # compute gradient and do Adam step\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        adj_previous = adj_learned.detach()  # Update adj_previous for the next iteration\n",
    "\n",
    "    lr_scheduler.step(top1.avg)\n",
    "\n",
    "    return top1.avg, losses.avg, f_1.avg, sensitivity.avg\n",
    "\n",
    "# %% [code]\n",
    "def validate(val_loader, model, criterion):\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    f_1 = AverageMeter('F1', ':6.2f')\n",
    "    sensitivity = AverageMeter('Sens', ':6.2f')\n",
    "\n",
    "    # Switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for count, (data, label) in enumerate(val_loader):\n",
    "            data = data.to(DEVICE).type(torch.float)\n",
    "            label = label.to(DEVICE).type(torch.float)\n",
    "\n",
    "            # Compute output\n",
    "            output, logvar, mean, adj_learned = model(data)\n",
    "\n",
    "            # Calculate KL divergence for the variational part (if it's part of the loss during evaluation)\n",
    "            kl_divergence = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "            primary_loss = criterion(output, label)\n",
    "\n",
    "            # Here, we use primary_loss directly for validation\n",
    "            # Since regularization and structural losses are typically training stabilizers\n",
    "            loss = primary_loss + kl_divergence  # You can include or exclude KL divergence based on your specific model requirements\n",
    "\n",
    "            # Measure accuracy and record loss\n",
    "            acc1 = balanced_accuracy_multi(output, label)\n",
    "            f1 = Fbeta_multi(output, label)\n",
    "            sens = recall_multi(output, label)\n",
    "\n",
    "            losses.update(loss.item(), data.size(0))\n",
    "            top1.update(acc1, data.size(0))\n",
    "            f_1.update(f1, data.size(0))\n",
    "            sensitivity.update(sens, data.size(0))\n",
    "\n",
    "            # Optional: Clean-up and memory management\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    return top1.avg, losses.avg, f_1.avg, sensitivity.avg"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# run the training iterations\n",
    "loss_train = []\n",
    "acc_train = []\n",
    "loss_val = []\n",
    "acc_val = []\n",
    "epoches = []\n",
    "f1_train = []\n",
    "f1_val = []\n",
    "sens_train = []\n",
    "sens_val = []\n",
    "\n",
    "# init acc\n",
    "best_acc1 = 0\n",
    "best_f1 = 0\n",
    "best_sens = 0\n",
    "num_graphs = 6  # Example value, adjust according to your model\n",
    "num_nodes = X_val.size(-2)  # Assuming X_val is your validation dataset tensor\n",
    "adj_original = initialize_adj_original(num_graphs, 48)\n",
    "\n",
    "for epoch in range(100):\n",
    "    epoches += [epoch]\n",
    "\n",
    "    # train for one epoch\n",
    "    acc_train_per, loss_train_per, f1_train_per, sens_train_per = train(train_loader, model, criterion, optimizer, lr_scheduler,adj_original)\n",
    "\n",
    "    acc_train += [acc_train_per]\n",
    "    loss_train += [loss_train_per]\n",
    "    f1_train += [f1_train_per]\n",
    "    sens_train += [sens_train_per]\n",
    "\n",
    "    msg = f'TRAIN, epoch {epoch}, loss {loss_train_per}, acc {acc_train_per}'\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc_val_per, loss_val_per, f1_val_per, sens_val_per = validate(val_loader, model, criterion)\n",
    "\n",
    "    acc_val += [acc_val_per]\n",
    "    loss_val += [loss_val_per]\n",
    "    f1_val += [f1_val_per]\n",
    "    sens_val += [sens_val_per]\n",
    "\n",
    "    print(f'VAL, loss {loss_val_per}, acc {acc_val_per}, f1 {f1_val_per}, sens {sens_val_per}')\n",
    "\n",
    "    # remember best acc\n",
    "    best_acc1 = max(acc_val_per, best_acc1)\n",
    "    best_f1 = max(f1_val_per, best_f1)\n",
    "    best_sens = max(sens_val_per, best_sens)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "tGP1UVi7H46y",
    "outputId": "99d4865e-7003-463e-e7ed-a6db78a06ace"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6680, device='cuda:0') tensor(0.4396, device='cuda:0') tensor(0.4252, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('models/DynaGraph_42.pt')\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for count, (data, label) in enumerate(test_loader):\n",
    "\n",
    "        data = data.to(DEVICE).type(torch.float)\n",
    "        label = label.to(DEVICE).type(torch.float)\n",
    "\n",
    "        # compute output\n",
    "        output = model(data)[0]\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1 = balanced_accuracy_multi(output, label)\n",
    "        f1 = Fbeta_multi(output, label)\n",
    "        sens = recall_multi(output, label)\n",
    "\n",
    "        print(acc1, f1, sens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "74rJPR8nH46z",
    "outputId": "16ad1846-736d-405a-beec-8e7b95e715fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6942, device='cuda:0'),\n",
       " tensor(0.4245, device='cuda:0'),\n",
       " tensor(0.5754, device='cuda:0'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc1, best_f1, best_sens"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1nEXRKOpikAMjc0QX3ZLTdwWAOl13u90P",
     "timestamp": 1705338972763
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
