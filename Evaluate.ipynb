{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries and packages\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import init\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Seeds we tried: 42, 1992, 250, 213, 1709\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmesinovic\\AppData\\Local\\Temp\\ipykernel_17456\\121165920.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_dataset = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load('Data/eICU Data/X_test_multilabel_full_42.npy', mmap_mode='c')\n",
    "y_test = np.load('Data/eICU Data/y_test_multilabel_full_42.npy', mmap_mode='c')\n",
    "\n",
    "X_test = np.swapaxes(X_test, 1, 2)\n",
    "\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "X_test = X_test[:, None, :, :]\n",
    "assert X_test.shape == (230, 1, 80, 24)\n",
    "\n",
    "# init [num_variables, seq_length, num_classes]\n",
    "num_nodes = X_val.size(-2)\n",
    "\n",
    "seq_length = X_val.size(-1)\n",
    "\n",
    "num_classes = 5\n",
    "\n",
    "# convert data & labels to TensorDataset\n",
    "test_dataset = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                            batch_size=230,\n",
    "                                            shuffle=False,\n",
    "                                            pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "# %% [code]\n",
    "class multi_shallow_embedding(nn.Module):\n",
    "\n",
    "    def __init__(self, num_nodes, k_neighs, num_graphs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_nodes = num_nodes\n",
    "        self.k = k_neighs\n",
    "        self.num_graphs = num_graphs\n",
    "\n",
    "        self.emb_s = Parameter(Tensor(num_graphs, num_nodes, 1))\n",
    "        self.emb_t = Parameter(Tensor(num_graphs, 1, num_nodes))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.xavier_uniform_(self.emb_s)\n",
    "        init.xavier_uniform_(self.emb_t)\n",
    "\n",
    "\n",
    "    def forward(self, device):\n",
    "\n",
    "        # adj: [G, N, N]\n",
    "        adj = torch.matmul(self.emb_s, self.emb_t).to(device)\n",
    "\n",
    "        # remove self-loop\n",
    "        adj = adj.clone()\n",
    "        idx = torch.arange(self.num_nodes, dtype=torch.long, device=device)\n",
    "        adj[:, idx, idx] = float('-inf')\n",
    "\n",
    "        # top-k-edge adj\n",
    "        adj_flat = adj.reshape(self.num_graphs, -1)\n",
    "        indices = adj_flat.topk(k=self.k)[1].reshape(-1)\n",
    "\n",
    "        idx = torch.tensor([ i//self.k for i in range(indices.size(0)) ], device=device)\n",
    "\n",
    "        adj_flat = torch.zeros_like(adj_flat).clone()\n",
    "        adj_flat[idx, indices] = 1.\n",
    "        adj = adj_flat.reshape_as(adj)\n",
    "\n",
    "        return adj\n",
    "\n",
    "\n",
    "class Group_Linear(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, groups=1, bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.groups = groups\n",
    "\n",
    "        self.group_mlp = nn.Conv2d(in_channels * groups, out_channels * groups, kernel_size=(1, 1), groups=groups, bias=bias)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.group_mlp.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor, is_reshape: False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): [B, C, N, F] (if not is_reshape), [B, C, G, N, F//G] (if is_reshape)\n",
    "        \"\"\"\n",
    "        B = x.size(0)\n",
    "        C = x.size(1)\n",
    "        N = x.size(-2)\n",
    "        G = self.groups\n",
    "\n",
    "        if not is_reshape:\n",
    "            # x: [B, C_in, G, N, F//G]\n",
    "            x = x.reshape(B, C, N, G, -1).transpose(2, 3)\n",
    "        # x: [B, G*C_in, N, F//G]\n",
    "        x = x.transpose(1, 2).reshape(B, G*C, N, -1)\n",
    "\n",
    "        out = self.group_mlp(x)\n",
    "        out = out.reshape(B, G, self.out_channels, N, -1).transpose(1, 2)\n",
    "\n",
    "        # out: [B, C_out, G, N, F//G]\n",
    "        return out\n",
    "\n",
    "\n",
    "class DenseGCNConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, groups=1, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.lin = Group_Linear(in_channels, out_channels, groups, bias=False)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        init.zeros_(self.bias)\n",
    "\n",
    "    def norm(self, adj: Tensor, add_loop):\n",
    "        if add_loop:\n",
    "            adj = adj.clone()\n",
    "            idx = torch.arange(adj.size(-1), dtype=torch.long, device=adj.device)\n",
    "            adj[:, idx, idx] += 1\n",
    "\n",
    "        deg_inv_sqrt = adj.sum(-1).clamp(min=1).pow(-0.5)\n",
    "\n",
    "        adj = deg_inv_sqrt.unsqueeze(-1) * adj * deg_inv_sqrt.unsqueeze(-2)\n",
    "\n",
    "        return adj\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor, adj: Tensor, add_loop=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): [B, C, N, F]\n",
    "            adj (Tensor): [B, G, N, N]\n",
    "        \"\"\"\n",
    "        adj = self.norm(adj, add_loop).unsqueeze(1)\n",
    "\n",
    "        # x: [B, C, G, N, F//G]\n",
    "        x = self.lin(x, False)\n",
    "\n",
    "        out = torch.matmul(adj, x)\n",
    "\n",
    "        # out: [B, C, N, F]\n",
    "        B, C, _, N, _ = out.size()\n",
    "        out = out.transpose(2, 3).reshape(B, C, N, -1)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out = out.transpose(1, -1) + self.bias\n",
    "            out = out.transpose(1, -1)\n",
    "\n",
    "        return out\n",
    "\n",
    "class DenseGINConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, groups=1, eps=0, train_eps=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp = Group_Linear(in_channels, out_channels, groups, bias=False)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder_mean = Group_Linear(in_channels, out_channels, groups, bias=False)\n",
    "        self.encoder_logvar = Group_Linear(in_channels, out_channels, groups, bias=False)\n",
    "\n",
    "        # Decoder\n",
    "        self.mlp = Group_Linear(out_channels, in_channels, groups, bias=False)  # Adjust output channels\n",
    "\n",
    "\n",
    "        self.init_eps = eps\n",
    "        if train_eps:\n",
    "            self.eps = Parameter(Tensor([eps]))\n",
    "        else:\n",
    "            self.register_buffer('eps', Tensor([eps]))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.mlp.reset_parameters()\n",
    "        self.eps.data.fill_(self.init_eps)\n",
    "\n",
    "    def norm(self, adj: Tensor, add_loop):\n",
    "        if add_loop:\n",
    "            adj = adj.clone()\n",
    "            idx = torch.arange(adj.size(-1), dtype=torch.long, device=adj.device)\n",
    "            adj[..., idx, idx] += 1\n",
    "\n",
    "        deg_inv_sqrt = adj.sum(-1).clamp(min=1).pow(-0.5)\n",
    "\n",
    "        adj = deg_inv_sqrt.unsqueeze(-1) * adj * deg_inv_sqrt.unsqueeze(-2)\n",
    "\n",
    "        return adj\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        # Add an epsilon to prevent very large values\n",
    "        epsilon = 1e-7\n",
    "        std = torch.exp(0.5 * logvar) + epsilon\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def forward(self, x: Tensor, adj: Tensor, add_loop=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): [B, C, N, F]\n",
    "            adj (Tensor): [G, N, N]\n",
    "        \"\"\"\n",
    "        B, C, N, _ = x.size()\n",
    "        G = adj.size(0)\n",
    "\n",
    "        # adj-norm\n",
    "        adj = self.norm(adj, add_loop=False)\n",
    "\n",
    "        # x: [B, C, G, N, F//G]\n",
    "        x = x.reshape(B, C, N, G, -1).transpose(2, 3)\n",
    "\n",
    "        out = torch.matmul(adj, x)\n",
    "\n",
    "        # DYNAMIC\n",
    "        x_pre = x[:, :, :-1, ...]\n",
    "\n",
    "        # out = x[:, :, 1:, ...] + x_pre\n",
    "        out[:, :, 1:, ...] = out[:, :, 1:, ...] + x_pre\n",
    "        # out = torch.cat( [x[:, :, 0, ...].unsqueeze(2), out], dim=2 )\n",
    "\n",
    "        if add_loop:\n",
    "            out = (1 + self.eps) * x + out\n",
    "\n",
    "        # out: [B, C, G, N, F//G]\n",
    "        out = self.mlp(out, True)\n",
    "\n",
    "        # out: [B, C, N, F]\n",
    "        C = out.size(1)\n",
    "        out2 = out.transpose(2, 3).reshape(B, C, N, -1)\n",
    "\n",
    "        # Variational encoding\n",
    "        mean = self.mlp(x,True)\n",
    "        logvar = self.mlp(x,True)\n",
    "\n",
    "\n",
    "        return out2 , logvar, mean\n",
    "\n",
    "class Dense_TimeDiffPool2d(nn.Module):\n",
    "\n",
    "    def __init__(self, pre_nodes, pooled_nodes, kern_size, padding):\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO: add Normalization\n",
    "        self.time_conv = nn.Conv2d(pre_nodes, pooled_nodes, (1, kern_size), padding=(0, padding))\n",
    "\n",
    "        self.re_param = Parameter(Tensor(kern_size, 1))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.time_conv.reset_parameters()\n",
    "        init.kaiming_uniform_(self.re_param, nonlinearity='relu')\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor, adj: Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): [B, C, N, F]\n",
    "            adj (Tensor): [G, N, N]\n",
    "        \"\"\"\n",
    "        x = x.transpose(1, 2)\n",
    "        out = self.time_conv(x)\n",
    "        out = out.transpose(1, 2)\n",
    "\n",
    "        # s: [ N^(l+1), N^l, 1, K ]\n",
    "        s = torch.matmul(self.time_conv.weight, self.re_param).view(out.size(-2), -1)\n",
    "\n",
    "        out_adj = torch.matmul(torch.matmul(s, adj), s.transpose(0, 1))\n",
    "\n",
    "        return out, out_adj\n",
    "\n",
    "class GNNStack(nn.Module):\n",
    "\n",
    "    def __init__(self, gnn_model_type, num_layers, groups, pool_ratio, kern_size,\n",
    "                 in_dim, hidden_dim, out_dim,\n",
    "                 seq_len, num_nodes, num_classes, dropout=0.7, activation=nn.ReLU()):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention_matrix = nn.Parameter(torch.randn(groups, num_nodes, num_nodes))\n",
    "        nn.init.xavier_uniform_(self.attention_matrix)\n",
    "        #******************************************************************************\n",
    "\n",
    "        k_neighs = self.num_nodes = num_nodes\n",
    "\n",
    "        self.num_graphs = groups\n",
    "\n",
    "        self.num_feats = seq_len\n",
    "        if seq_len % groups:\n",
    "            self.num_feats += ( groups - seq_len % groups )\n",
    "        self.g_constr = multi_shallow_embedding(num_nodes, k_neighs, self.num_graphs)\n",
    "\n",
    "        gnn_model, heads = self.build_gnn_model(gnn_model_type)\n",
    "\n",
    "        assert num_layers >= 1, 'Error: Number of layers is invalid.'\n",
    "        assert num_layers == len(kern_size), 'Error: Number of kernel_size should equal to number of layers.'\n",
    "        paddings = [ (k - 1) // 2 for k in kern_size ]\n",
    "\n",
    "        self.tconvs = nn.ModuleList(\n",
    "            [nn.Conv2d(1, in_dim, (1, kern_size[0]), padding=(0, paddings[0]))] +\n",
    "            [nn.Conv2d(heads * in_dim, hidden_dim, (1, kern_size[layer+1]), padding=(0, paddings[layer+1])) for layer in range(num_layers - 2)] +\n",
    "            [nn.Conv2d(heads * hidden_dim, out_dim, (1, kern_size[-1]), padding=(0, paddings[-1]))]\n",
    "        )\n",
    "\n",
    "        self.lstm_layers = nn.ModuleList()\n",
    "        self.lstm_layers.append(nn.RNN(input_size=24, hidden_size=in_dim * 24, batch_first=True))\n",
    "        for _ in range(1, num_layers - 2):\n",
    "            self.lstm_layers.append(nn.RNN(input_size=in_dim * 24, hidden_size=hidden_dim * 24, batch_first=True))\n",
    "        self.lstm_layers.append(nn.RNN(input_size=hidden_dim * 24, hidden_size=out_dim * 24, batch_first=True))\n",
    "\n",
    "        self.gconvs = nn.ModuleList(\n",
    "            [gnn_model(in_dim, heads * in_dim, groups)] +\n",
    "            [gnn_model(hidden_dim, heads * hidden_dim, groups) for _ in range(num_layers - 2)] +\n",
    "            [gnn_model(out_dim, heads * out_dim, groups)]\n",
    "        )\n",
    "\n",
    "        self.bns = nn.ModuleList(\n",
    "            [nn.BatchNorm2d(heads * in_dim)] +\n",
    "            [nn.BatchNorm2d(heads * hidden_dim) for _ in range(num_layers - 2)] +\n",
    "            [nn.BatchNorm2d(heads * out_dim)]\n",
    "        )\n",
    "\n",
    "        self.left_num_nodes = []\n",
    "        for layer in range(num_layers + 1):\n",
    "            left_node = round( num_nodes * (1 - (pool_ratio*layer)) )\n",
    "            if left_node > 0:\n",
    "                self.left_num_nodes.append(left_node)\n",
    "            else:\n",
    "                self.left_num_nodes.append(1)\n",
    "        self.diffpool = nn.ModuleList(\n",
    "            [Dense_TimeDiffPool2d(self.left_num_nodes[layer], self.left_num_nodes[layer+1], kern_size[layer], paddings[layer]) for layer in range(num_layers - 1)] +\n",
    "            [Dense_TimeDiffPool2d(self.left_num_nodes[-2], self.left_num_nodes[-1], kern_size[-1], paddings[-1])]\n",
    "        )\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.activation = activation\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.linear = nn.Linear(heads * out_dim, num_classes)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lstm, gconv, bn, pool in zip(self.lstm_layers, self.gconvs, self.bns, self.diffpool):\n",
    "            lstm.reset_parameters()\n",
    "            gconv.reset_parameters()\n",
    "            bn.reset_parameters()\n",
    "            pool.reset_parameters()\n",
    "\n",
    "        self.linear.reset_parameters()\n",
    "\n",
    "    def build_gnn_model(self, model_type):\n",
    "        if model_type == 'dyGCN2d':\n",
    "            return DenseGCNConv2d, 1\n",
    "        if model_type == 'DenseGINConv2d':\n",
    "            return DenseGINConv2d, 1\n",
    "\n",
    "\n",
    "    def forward(self, inputs: Tensor):\n",
    "\n",
    "        if inputs.size(-1) % self.num_graphs:\n",
    "            pad_size = (self.num_graphs - inputs.size(-1) % self.num_graphs) / 2\n",
    "            x = F.pad(inputs, (int(pad_size), ceil(pad_size)), mode='constant', value=0.0)\n",
    "        else:\n",
    "            x = inputs\n",
    "\n",
    "        adj = self.g_constr(x.device)\n",
    "   \n",
    "        #*******************************************************************\n",
    "        # Attention layer \n",
    "        attention_scores = F.softmax(self.attention_matrix, dim=-1)  \n",
    "        adj = adj * attention_scores \n",
    "        # print(attention_scores,\"attention_scores\")\n",
    "        #*******************************************************************    \n",
    "        \n",
    "        for lstm, gconv, bn, pool in zip(self.lstm_layers, self.gconvs, self.bns, self.diffpool):           \n",
    "            s=x.shape[1]\n",
    "            if s==1:\n",
    "               x1=x.repeat(1, 128, 1,1)\n",
    "            else:\n",
    "               x1=x.repeat(1, 2, 1,1)    \n",
    "            batch_size, channels, seq_len, features = x.size()\n",
    "            x = x.view(batch_size, seq_len, channels * features)\n",
    "            # Apply LSTM layer\n",
    "            x, _ = lstm(x)\n",
    "            x = torch.reshape(x, (batch_size, -1, seq_len, features))\n",
    "            x=x+x1\n",
    "\n",
    "            temp, logvar, mean = gconv(x, adj)\n",
    "            \n",
    "            x, adj = pool(temp, adj)\n",
    "\n",
    "            x = self.activation(bn(x))\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            \n",
    "\n",
    "        out = self.global_pool(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out,logvar, mean,adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Metrics\n",
    "# %% [code]\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "# %% [code]\n",
    "def balanced_accuracy_multi(inp, targ, thresh=0.5, sigmoid=True):\n",
    "    \"Computes balanced accuracy when `inp` and `targ` are the same size.\"\n",
    "\n",
    "    if sigmoid: inp = inp.sigmoid()\n",
    "    pred = inp>thresh\n",
    "\n",
    "    correct = pred==targ.bool()\n",
    "    TP = torch.logical_and(correct,  (targ==1).bool()).sum()\n",
    "    TN = torch.logical_and(correct,  (targ==0).bool()).sum()\n",
    "    FN = torch.logical_and(~correct, (targ==1).bool()).sum()\n",
    "    FP = torch.logical_and(~correct, (targ==0).bool()).sum()\n",
    "\n",
    "    TPR = TP/(TP+FN)\n",
    "    TNR = TN/(TN+FP)\n",
    "    balanced_accuracy = (TPR+TNR)/2\n",
    "    return balanced_accuracy\n",
    "\n",
    "# %% [code]\n",
    "def Fbeta_multi(inp, targ, beta=1.0, thresh=0.5, sigmoid=True):\n",
    "    \"Computes Fbeta when `inp` and `targ` are the same size.\"\n",
    "\n",
    "    if sigmoid: inp = inp.sigmoid()\n",
    "    pred = inp>thresh\n",
    "\n",
    "    correct = pred==targ.bool()\n",
    "    TP = torch.logical_and(correct,  (targ==1).bool()).sum()\n",
    "    TN = torch.logical_and(correct,  (targ==0).bool()).sum()\n",
    "    FN = torch.logical_and(~correct, (targ==1).bool()).sum()\n",
    "    FP = torch.logical_and(~correct, (targ==0).bool()).sum()\n",
    "\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    beta2 = beta*beta\n",
    "\n",
    "    if precision+recall > 0:\n",
    "        Fbeta = (1+beta2)*precision*recall/(beta2*precision+recall)\n",
    "    else:\n",
    "        Fbeta = 0\n",
    "    return Fbeta\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "def recall_multi(inp, targ, thresh=0.5, sigmoid=True):\n",
    "    \"Computes recall when `inp` and `targ` are the same size.\"\n",
    "\n",
    "    if sigmoid: inp = inp.sigmoid()\n",
    "    pred = inp>thresh\n",
    "\n",
    "    correct = pred==targ.bool()\n",
    "    TP = torch.logical_and(correct,  (targ==1).bool()).sum()\n",
    "    FN = torch.logical_and(~correct, (targ==1).bool()).sum()\n",
    "\n",
    "    recall = TP/(TP+FN)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6seT1-CkH46o",
    "outputId": "48245d5a-3805-4251-86b5-f7c22072ceed"
   },
   "outputs": [],
   "source": [
    "model = GNNStack(gnn_model_type='DenseGINConv2d', num_layers=2,\n",
    "                     groups=6, pool_ratio=0.2, kern_size=[11, 3],\n",
    "                     in_dim=128, hidden_dim=128, out_dim=256,\n",
    "                     seq_len=seq_length, num_nodes=num_nodes, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "tGP1UVi7H46y",
    "outputId": "99d4865e-7003-463e-e7ed-a6db78a06ace"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6721) tensor(0.4581) tensor(0.4128)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('models/eICU_1992.pt', map_location=torch.device('cpu'))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for count, (data, label) in enumerate(test_loader):\n",
    "\n",
    "        data = data.to(DEVICE).type(torch.float)\n",
    "        label = label.to(DEVICE).type(torch.float)\n",
    "\n",
    "        # compute output\n",
    "        output = model(data)[0]\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1 = balanced_accuracy_multi(output, label)\n",
    "        f1 = Fbeta_multi(output, label)\n",
    "        sens = recall_multi(output, label)\n",
    "\n",
    "        print(acc1, f1, sens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1nEXRKOpikAMjc0QX3ZLTdwWAOl13u90P",
     "timestamp": 1705338972763
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
